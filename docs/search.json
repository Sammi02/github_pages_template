[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Welcome to My Data Science Portfolio",
    "section": "",
    "text": "Hi there — I’m Sammi Hilton, a data analyst that turns raw data into meaningful insights. I love exploring how data can drive smarter decisions, whether that’s through building dashboards, automating data pipelines, or uncovering patterns with statistical analysis and machine learning.\nThis portfolio showcases projects that highlight my skills in Python, data visualization, modeling, and data cleaning, as well as my experience working with complex datasets. My goal is to keep learning, share what I build, and show how thoughtful analysis can make a real impact.\n\n\nThis portfolio shows my work learning data science. Each project includes:\n\nMy code with documentation\nVisualizations I created\nWhat I learned and discovered\n\nI built this site using Quarto and host it on GitHub Pages.\n\n\n\n\nProgramming: Python, Pandas for data analysis\nVisualization: Creating charts with Matplotlib and Seaborn\nData Collection: Getting data from files, websites, and APIs\nAnalysis: Finding patterns and answering questions with data\n\n\n\n\n\n\n\nLearn how I explore datasets to find interesting patterns and answer questions.\n\n\n\nSee how I gather data from different sources and prepare it for analysis.\n\n\n\nSee how I tackle a data science project beginning to end.\n\n\n\nThanks for visiting! Feel free to explore my projects and see what I’m learning."
  },
  {
    "objectID": "index.html#about-this-portfolio",
    "href": "index.html#about-this-portfolio",
    "title": "Welcome to My Data Science Portfolio",
    "section": "",
    "text": "This portfolio shows my work learning data science. Each project includes:\n\nMy code with documentation\nVisualizations I created\nWhat I learned and discovered\n\nI built this site using Quarto and host it on GitHub Pages."
  },
  {
    "objectID": "index.html#skills-im-learning",
    "href": "index.html#skills-im-learning",
    "title": "Welcome to My Data Science Portfolio",
    "section": "",
    "text": "Programming: Python, Pandas for data analysis\nVisualization: Creating charts with Matplotlib and Seaborn\nData Collection: Getting data from files, websites, and APIs\nAnalysis: Finding patterns and answering questions with data"
  },
  {
    "objectID": "index.html#my-projects",
    "href": "index.html#my-projects",
    "title": "Welcome to My Data Science Portfolio",
    "section": "",
    "text": "Learn how I explore datasets to find interesting patterns and answer questions.\n\n\n\nSee how I gather data from different sources and prepare it for analysis.\n\n\n\nSee how I tackle a data science project beginning to end.\n\n\n\nThanks for visiting! Feel free to explore my projects and see what I’m learning."
  },
  {
    "objectID": "projects/index.html",
    "href": "projects/index.html",
    "title": "Projects Overview",
    "section": "",
    "text": "Description: Pick a dataset and explore it to discover insights and answer questions.\n\n\n\nDescription: Find an interesting data source, collect the data, and prepare it for analysis.\n\n\n\nDescription: A comprehensive project that shows off my data science skills.",
    "crumbs": [
      "Projects Overview"
    ]
  },
  {
    "objectID": "projects/index.html#all-projects",
    "href": "projects/index.html#all-projects",
    "title": "Projects Overview",
    "section": "",
    "text": "Description: Pick a dataset and explore it to discover insights and answer questions.\n\n\n\nDescription: Find an interesting data source, collect the data, and prepare it for analysis.\n\n\n\nDescription: A comprehensive project that shows off my data science skills.",
    "crumbs": [
      "Projects Overview"
    ]
  },
  {
    "objectID": "projects/eda.html",
    "href": "projects/eda.html",
    "title": "EDA Project",
    "section": "",
    "text": "This is coming down the pipeline. Check again later.",
    "crumbs": [
      "EDA Project"
    ]
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About Me",
    "section": "",
    "text": "I am currently pursuing a degree in Statistics with an emphasis in Data Science and will graduate in April 2026. My studies have given me a strong foundation in statistical methods, data analysis, and programming, as well as hands-on experience with tools such as Python, SQL, R, and Power BI.\nI became interested in data science because I enjoy uncovering patterns in data and using them to create a story. Some of my projects have included analyzing survey data to understand Net Promoter Score (NPS) trends, building interactive dashboards to track business and marketing performance, and working with large datasets to clean, transform, and visualize insights.\nMy career goal is to become a data analyst or data scientist, where I can apply my skills in statistics and data science to support data-driven decision-making and create clear, actionable insights for organizations."
  },
  {
    "objectID": "about.html#background",
    "href": "about.html#background",
    "title": "About Me",
    "section": "",
    "text": "I am currently pursuing a degree in Statistics with an emphasis in Data Science and will graduate in April 2026. My studies have given me a strong foundation in statistical methods, data analysis, and programming, as well as hands-on experience with tools such as Python, SQL, R, and Power BI.\nI became interested in data science because I enjoy uncovering patterns in data and using them to create a story. Some of my projects have included analyzing survey data to understand Net Promoter Score (NPS) trends, building interactive dashboards to track business and marketing performance, and working with large datasets to clean, transform, and visualize insights.\nMy career goal is to become a data analyst or data scientist, where I can apply my skills in statistics and data science to support data-driven decision-making and create clear, actionable insights for organizations."
  },
  {
    "objectID": "about.html#education",
    "href": "about.html#education",
    "title": "About Me",
    "section": "Education",
    "text": "Education\n\nStatistics: Data Science - Brigham Young University, April 2026\nRelevant Coursework: Statistics, Data Analysis, Programming, Python, C++, R, Excel, Data Visualization, SQL, Probability & Inference."
  },
  {
    "objectID": "about.html#skills-interests",
    "href": "about.html#skills-interests",
    "title": "About Me",
    "section": "Skills & Interests",
    "text": "Skills & Interests\n\nTechnical Skills\n\nProgramming: Python, SQL, C++, R, Excel, Tableau, Power BI\nData Analysis: Pandas, NumPy\nVisualization: Matplotlib, Seaborn, Tableau, Power BI, GGplot\nMachine Learning: Scikit-learn\nTools: Jupyter Notebooks, Git/GitHub\n\n\n\nAreas of Interest\n\nMarketing Analytics\nBiostatistics"
  },
  {
    "objectID": "about.html#goals",
    "href": "about.html#goals",
    "title": "About Me",
    "section": "Goals",
    "text": "Goals\nIn the short term, my main objective is to strengthen my technical skills in Python, SQL, R, and data visualization tools while gaining more experience applying statistical methods to real datasets. I want to build confidence in analyzing marketing data, such as campaign performance, customer behavior, and survey responses, and learn how to clearly communicate insights through dashboards and reports.\nIn the long term, I aspire to pursue a career in marketing analytics or data science, where I can use data to help organizations make smarter decisions about customer engagement, advertising strategies, and overall business growth.\nUltimately, I hope to become a professional who can bridge the gap between technical analysis and business strategy by providing insights that directly drive better outcomes."
  },
  {
    "objectID": "about.html#contact",
    "href": "about.html#contact",
    "title": "About Me",
    "section": "Contact",
    "text": "Contact\n\nEmail: sammirasbands@gmail.com\nGitHub: github.com/Sammi02\nLinkedIn: linkedin.com/in/sammi-hilton\n\n\n\n\n\nThis portfolio showcases my learning progress and projects completed during my data science studies."
  },
  {
    "objectID": "projects/data-acquisition.html",
    "href": "projects/data-acquisition.html",
    "title": "Data Acquisition Project",
    "section": "",
    "text": "This is coming down the pipeline. Check again later.",
    "crumbs": [
      "Data Acquisition Project"
    ]
  },
  {
    "objectID": "projects/final-project.html",
    "href": "projects/final-project.html",
    "title": "Final Project",
    "section": "",
    "text": "This is coming down the pipeline. Check again later.",
    "crumbs": [
      "Final Project"
    ]
  },
  {
    "objectID": "Blog.html",
    "href": "Blog.html",
    "title": "Data Joining Made Simple",
    "section": "",
    "text": "In data science, joining datasets is a foundational skill because real-world data rarely comes in one perfect table. Most of the time, data is scattered across multiple sources. One file could contain customer information, while another file could contain order information. To analyze and make sense of data, we need to join datasets together to create a clear story from the data. Without joining datasets, an analysis could remain incomplete or misleading because the data scientist didn’t have all the information. This could lead to misinformed decisions for businesses.\nIn this tutorial, you will learn how to join two small datasets on a common key. We’ll go over four types of joins: inner join, outer join, left join, and right join. This will be done in Python using pandas. By the end of this tutorial, you will feel confident in your understanding of joining two tables together.\n\n\n\n\nWe will start by creating two small datasets! One will have customer information in it and the other one will have customer orders in it. To create data tables, you will need to import pandas!\n\n\nCode\nimport pandas as pd\n\n\n# Customers dataset\ncustomers = pd.DataFrame({\n   \"customer_id\": [1, 2, 3],\n   \"first_name\": [\"Alice\", \"Bob\", \"Sally\"],\n   \"last_name\": [\"Smith\", \"Robinson\", \"Johnson\"]\n})\n\n\n# Orders dataset\norders = pd.DataFrame({\n   \"order_id\": [101, 102, 103, 104, 105, 106],\n   \"customer_id\": [1, 2, 2, 4, 5, 6],\n   \"amount\": [50, 25, 75, 100, 150, 60],\n   \"product\": [\"Books\", \"Pens\", \"Backpack\", \"Backpack\", \"Books\", \"Books\"]\n})\n\n\nprint(customers)\nprint(orders)\n\n\n   customer_id first_name last_name\n0            1      Alice     Smith\n1            2        Bob  Robinson\n2            3      Sally   Johnson\n   order_id  customer_id  amount   product\n0       101            1      50     Books\n1       102            2      25      Pens\n2       103            2      75  Backpack\n3       104            4     100  Backpack\n4       105            5     150     Books\n5       106            6      60     Books\n\n\n\n\n\nWhen joining two datasets, you need a column that both tables share. This column is called the join key.\nIn our example:\n\nCustomers table has columns:\n\ncustomer_id\n\nfirst_name\n\nlast_name\n\nOrders table has columns:\n\norder_id\n\ncustomer_id\n\namount\n\nproduct\n\n\nBoth of these tables have a column called customer_id so that is our join key!\n\n\n\nIn pandas, the merge function is used to combine two DataFrames. In the merge function, you first specify your two dataframes. After that, you specify your common key by using the on argument. The main parameter that controls how they are combined is the how argument, which can take values like \"inner\", \"outer\", \"left\", and \"right\".\n\n\nThis is the most common type of join. An inner join keeps only the rows that have common characteristics in both tables.\n\n\nCode\ninner_join = pd.merge(customers, orders, on=\"customer_id\", how=\"inner\")\ninner_join\n\n\n\n\n\n\n\n\n\ncustomer_id\nfirst_name\nlast_name\norder_id\namount\nproduct\n\n\n\n\n0\n1\nAlice\nSmith\n101\n50\nBooks\n\n\n1\n2\nBob\nRobinson\n102\n25\nPens\n\n\n2\n2\nBob\nRobinson\n103\n75\nBackpack\n\n\n\n\n\n\n\nIn this example, only customers who are found in both tables are shown. Alice (customer_id 1) appears once because she placed one order. Bob (customer_id 2) appears twice because he has two orders, so he shows up once for each of them. Sally (customer_id 3) is missing, because she has no orders, and customers 4, 5, and 6 are missing because they don’t exist in the customers table.\n\n\n\nAn outer join keeps all rows from both tables. If a match does not exist, pandas fills in missing values with NaN.\n\n\nCode\nouter_join = pd.merge(customers, orders, on=\"customer_id\", how=\"outer\")\nouter_join\n\n\n\n\n\n\n\n\n\ncustomer_id\nfirst_name\nlast_name\norder_id\namount\nproduct\n\n\n\n\n0\n1\nAlice\nSmith\n101.0\n50.0\nBooks\n\n\n1\n2\nBob\nRobinson\n102.0\n25.0\nPens\n\n\n2\n2\nBob\nRobinson\n103.0\n75.0\nBackpack\n\n\n3\n3\nSally\nJohnson\nNaN\nNaN\nNaN\n\n\n4\n4\nNaN\nNaN\n104.0\n100.0\nBackpack\n\n\n5\n5\nNaN\nNaN\n105.0\n150.0\nBooks\n\n\n6\n6\nNaN\nNaN\n106.0\n60.0\nBooks\n\n\n\n\n\n\n\nIn this example, the outer join kept all the records from both tables! If something was in the orders table and not the customers table, it would still appear in the result with missing values for the customer information. Similarly, if a customer had no orders, they would still appear with blank order details.\n\n\n\nA left join keeps all the rows from the first table and matches rows from the next table given where it is possible. If a customer has no order, you’ll still see them in the joined table with missing values in the order columns.\n\n\nCode\nleft_join = pd.merge(customers, orders, on=\"customer_id\", how=\"left\")\nleft_join\n\n\n\n\n\n\n\n\n\ncustomer_id\nfirst_name\nlast_name\norder_id\namount\nproduct\n\n\n\n\n0\n1\nAlice\nSmith\n101.0\n50.0\nBooks\n\n\n1\n2\nBob\nRobinson\n102.0\n25.0\nPens\n\n\n2\n2\nBob\nRobinson\n103.0\n75.0\nBackpack\n\n\n3\n3\nSally\nJohnson\nNaN\nNaN\nNaN\n\n\n\n\n\n\n\nIn this example of a left join, all the customers were kept in the joined table, even if they didn’t have an order. This is useful if you want to see every customer you have, even if they haven’t placed an order yet.\n\n\n\nA right join is very similar to a left join, except that it keeps all rows from the right table.\n\n\nCode\nright_join = pd.merge(customers, orders, on=\"customer_id\", how=\"right\")\nright_join\n\n\n\n\n\n\n\n\n\ncustomer_id\nfirst_name\nlast_name\norder_id\namount\nproduct\n\n\n\n\n0\n1\nAlice\nSmith\n101\n50\nBooks\n\n\n1\n2\nBob\nRobinson\n102\n25\nPens\n\n\n2\n2\nBob\nRobinson\n103\n75\nBackpack\n\n\n3\n4\nNaN\nNaN\n104\n100\nBackpack\n\n\n4\n5\nNaN\nNaN\n105\n150\nBooks\n\n\n5\n6\nNaN\nNaN\n106\n60\nBooks\n\n\n\n\n\n\n\nThe right join is very similar to the left join, except it kept everything from the orders table and if something was missing, it would put an NaN there.\n\n\n\n\nHere’s a quick comparison of how the different join types behave generally:\n\n\n\n\n\n\n\n\nJoin Type\nRows Returned\nWhen to Use\n\n\n\n\nInner\nMatching keys only\nWhen you want overlap only\n\n\nLeft\nAll from left + matches from right\nWhen left table is your main table\n\n\nRight\nAll from right + matches from left\nWhen right table is your main table\n\n\nOuter\nAll rows from both tables\nWhen you want everything\n\n\n\n\n\n\nVenn diagrams of join types\n\n\n\n\n\nJoining dataset is a fundamental skill in data science! By understanding and knowing when to use each of the four types of joining, you can:\n\nCombine datasets from multiple sources or platforms\nAvoid losing data or having duplicates when merging\nMake your data science process more accurate and run smoothly\n\nCall to Action Try it yourself! Create your own 2 datasets (e.g., employees and departments, students and courses, or customers) and try merging them with each of the join types we discussed! The more you practice, the more you will understand about joining datasets together!\nFor more information about joining datasets, you can check out: pandas merge documentation and pandas User Guide: Merging, Joining, and Concatenating."
  },
  {
    "objectID": "Blog.html#introduction",
    "href": "Blog.html#introduction",
    "title": "Data Joining Made Simple",
    "section": "",
    "text": "In data science, joining datasets is a foundational skill because real-world data rarely comes in one perfect table. Most of the time, data is scattered across multiple sources. One file could contain customer information, while another file could contain order information. To analyze and make sense of data, we need to join datasets together to create a clear story from the data. Without joining datasets, an analysis could remain incomplete or misleading because the data scientist didn’t have all the information. This could lead to misinformed decisions for businesses.\nIn this tutorial, you will learn how to join two small datasets on a common key. We’ll go over four types of joins: inner join, outer join, left join, and right join. This will be done in Python using pandas. By the end of this tutorial, you will feel confident in your understanding of joining two tables together."
  },
  {
    "objectID": "Blog.html#step-1-import-pandas-and-create-datasets",
    "href": "Blog.html#step-1-import-pandas-and-create-datasets",
    "title": "Data Joining Made Simple",
    "section": "",
    "text": "We will start by creating two small datasets! One will have customer information in it and the other one will have customer orders in it. To create data tables, you will need to import pandas!\n\n\nCode\nimport pandas as pd\n\n\n# Customers dataset\ncustomers = pd.DataFrame({\n   \"customer_id\": [1, 2, 3],\n   \"first_name\": [\"Alice\", \"Bob\", \"Sally\"],\n   \"last_name\": [\"Smith\", \"Robinson\", \"Johnson\"]\n})\n\n\n# Orders dataset\norders = pd.DataFrame({\n   \"order_id\": [101, 102, 103, 104, 105, 106],\n   \"customer_id\": [1, 2, 2, 4, 5, 6],\n   \"amount\": [50, 25, 75, 100, 150, 60],\n   \"product\": [\"Books\", \"Pens\", \"Backpack\", \"Backpack\", \"Books\", \"Books\"]\n})\n\n\nprint(customers)\nprint(orders)\n\n\n   customer_id first_name last_name\n0            1      Alice     Smith\n1            2        Bob  Robinson\n2            3      Sally   Johnson\n   order_id  customer_id  amount   product\n0       101            1      50     Books\n1       102            2      25      Pens\n2       103            2      75  Backpack\n3       104            4     100  Backpack\n4       105            5     150     Books\n5       106            6      60     Books"
  },
  {
    "objectID": "Blog.html#step-2-understanding-the-common-key",
    "href": "Blog.html#step-2-understanding-the-common-key",
    "title": "Data Joining Made Simple",
    "section": "",
    "text": "When joining two datasets, you need a column that both tables share. This column is called the join key.\nIn our example:\n\nCustomers table has columns:\n\ncustomer_id\n\nfirst_name\n\nlast_name\n\nOrders table has columns:\n\norder_id\n\ncustomer_id\n\namount\n\nproduct\n\n\nBoth of these tables have a column called customer_id so that is our join key!"
  },
  {
    "objectID": "Blog.html#step-3-understanding-join-types",
    "href": "Blog.html#step-3-understanding-join-types",
    "title": "Data Joining Made Simple",
    "section": "",
    "text": "In pandas, the merge function is used to combine two DataFrames. In the merge function, you first specify your two dataframes. After that, you specify your common key by using the on argument. The main parameter that controls how they are combined is the how argument, which can take values like \"inner\", \"outer\", \"left\", and \"right\".\n\n\nThis is the most common type of join. An inner join keeps only the rows that have common characteristics in both tables.\n\n\nCode\ninner_join = pd.merge(customers, orders, on=\"customer_id\", how=\"inner\")\ninner_join\n\n\n\n\n\n\n\n\n\ncustomer_id\nfirst_name\nlast_name\norder_id\namount\nproduct\n\n\n\n\n0\n1\nAlice\nSmith\n101\n50\nBooks\n\n\n1\n2\nBob\nRobinson\n102\n25\nPens\n\n\n2\n2\nBob\nRobinson\n103\n75\nBackpack\n\n\n\n\n\n\n\nIn this example, only customers who are found in both tables are shown. Alice (customer_id 1) appears once because she placed one order. Bob (customer_id 2) appears twice because he has two orders, so he shows up once for each of them. Sally (customer_id 3) is missing, because she has no orders, and customers 4, 5, and 6 are missing because they don’t exist in the customers table.\n\n\n\nAn outer join keeps all rows from both tables. If a match does not exist, pandas fills in missing values with NaN.\n\n\nCode\nouter_join = pd.merge(customers, orders, on=\"customer_id\", how=\"outer\")\nouter_join\n\n\n\n\n\n\n\n\n\ncustomer_id\nfirst_name\nlast_name\norder_id\namount\nproduct\n\n\n\n\n0\n1\nAlice\nSmith\n101.0\n50.0\nBooks\n\n\n1\n2\nBob\nRobinson\n102.0\n25.0\nPens\n\n\n2\n2\nBob\nRobinson\n103.0\n75.0\nBackpack\n\n\n3\n3\nSally\nJohnson\nNaN\nNaN\nNaN\n\n\n4\n4\nNaN\nNaN\n104.0\n100.0\nBackpack\n\n\n5\n5\nNaN\nNaN\n105.0\n150.0\nBooks\n\n\n6\n6\nNaN\nNaN\n106.0\n60.0\nBooks\n\n\n\n\n\n\n\nIn this example, the outer join kept all the records from both tables! If something was in the orders table and not the customers table, it would still appear in the result with missing values for the customer information. Similarly, if a customer had no orders, they would still appear with blank order details.\n\n\n\nA left join keeps all the rows from the first table and matches rows from the next table given where it is possible. If a customer has no order, you’ll still see them in the joined table with missing values in the order columns.\n\n\nCode\nleft_join = pd.merge(customers, orders, on=\"customer_id\", how=\"left\")\nleft_join\n\n\n\n\n\n\n\n\n\ncustomer_id\nfirst_name\nlast_name\norder_id\namount\nproduct\n\n\n\n\n0\n1\nAlice\nSmith\n101.0\n50.0\nBooks\n\n\n1\n2\nBob\nRobinson\n102.0\n25.0\nPens\n\n\n2\n2\nBob\nRobinson\n103.0\n75.0\nBackpack\n\n\n3\n3\nSally\nJohnson\nNaN\nNaN\nNaN\n\n\n\n\n\n\n\nIn this example of a left join, all the customers were kept in the joined table, even if they didn’t have an order. This is useful if you want to see every customer you have, even if they haven’t placed an order yet.\n\n\n\nA right join is very similar to a left join, except that it keeps all rows from the right table.\n\n\nCode\nright_join = pd.merge(customers, orders, on=\"customer_id\", how=\"right\")\nright_join\n\n\n\n\n\n\n\n\n\ncustomer_id\nfirst_name\nlast_name\norder_id\namount\nproduct\n\n\n\n\n0\n1\nAlice\nSmith\n101\n50\nBooks\n\n\n1\n2\nBob\nRobinson\n102\n25\nPens\n\n\n2\n2\nBob\nRobinson\n103\n75\nBackpack\n\n\n3\n4\nNaN\nNaN\n104\n100\nBackpack\n\n\n4\n5\nNaN\nNaN\n105\n150\nBooks\n\n\n5\n6\nNaN\nNaN\n106\n60\nBooks\n\n\n\n\n\n\n\nThe right join is very similar to the left join, except it kept everything from the orders table and if something was missing, it would put an NaN there."
  },
  {
    "objectID": "Blog.html#step-4-quick-comparison-and-visual",
    "href": "Blog.html#step-4-quick-comparison-and-visual",
    "title": "Data Joining Made Simple",
    "section": "",
    "text": "Here’s a quick comparison of how the different join types behave generally:\n\n\n\n\n\n\n\n\nJoin Type\nRows Returned\nWhen to Use\n\n\n\n\nInner\nMatching keys only\nWhen you want overlap only\n\n\nLeft\nAll from left + matches from right\nWhen left table is your main table\n\n\nRight\nAll from right + matches from left\nWhen right table is your main table\n\n\nOuter\nAll rows from both tables\nWhen you want everything\n\n\n\n\n\n\nVenn diagrams of join types"
  },
  {
    "objectID": "Blog.html#conclusion-why-this-matters-and-call-to-action",
    "href": "Blog.html#conclusion-why-this-matters-and-call-to-action",
    "title": "Data Joining Made Simple",
    "section": "",
    "text": "Joining dataset is a fundamental skill in data science! By understanding and knowing when to use each of the four types of joining, you can: - Cobmine datasets from multiple sources or platforms - Avoid losing data or having duplicates when merging - Make your data science process more accurate and run smoothly\nCall to Action Try it yourself! Create your own 2 datasets (e.g., employees, students, customers) and try merging them with each of the join types we discussed!"
  },
  {
    "objectID": "Blog.html#conclusion",
    "href": "Blog.html#conclusion",
    "title": "Data Joining Made Simple",
    "section": "",
    "text": "Joining dataset is a fundamental skill in data science! By understanding and knowing when to use each of the four types of joining, you can:\n\nCombine datasets from multiple sources or platforms\nAvoid losing data or having duplicates when merging\nMake your data science process more accurate and run smoothly\n\nCall to Action Try it yourself! Create your own 2 datasets (e.g., employees and departments, students and courses, or customers) and try merging them with each of the join types we discussed! The more you practice, the more you will understand about joining datasets together!\nFor more information about joining datasets, you can check out: pandas merge documentation and pandas User Guide: Merging, Joining, and Concatenating."
  },
  {
    "objectID": "about.html#experience",
    "href": "about.html#experience",
    "title": "About Me",
    "section": "Experience",
    "text": "Experience\n\nBYU Broadcasting — Data Scientist\n\nWrote complex SQL queries in AWS Athena to analyze TV and marketing performance data.\n\nBuilt Domo dashboards to visualize trends and support data-driven decisions across teams.\n\nGained hands-on experience with cloud-based tools including AWS, Athena, and Domo.\n\n\n\n\nDevos Outdoor — Data Engineer\n\nAutomated ETL pipelines across 5+ platforms (Reviews.io, HubSpot, QuickBooks, Luminous, etc.) by developing Python scripts for API integrations and centralizing data in MySQL.\n\nPartnered with the CFO and executive leadership to define KPIs and build Power BI dashboards for insights.\n\nDeveloped and deployed interactive, real-time Power BI dashboards to guide strategy.\n\n\n\n\nMissionary Training Center — Research Data Analyst\n\nAnalyzed student survey data in R, running regressions, t-tests, and exploratory data analysis to identify NPS trends and predictors.\n\nPresented findings to non-technical stakeholders, influencing program improvements.\n\nConducted and coded 20+ student interviews to assess survey comprehension and highlight improvement areas."
  },
  {
    "objectID": "about.html#get-to-know-me",
    "href": "about.html#get-to-know-me",
    "title": "About Me",
    "section": "Get to Know Me",
    "text": "Get to Know Me\n\nI love to ski, run, and hike!\nI am fluent in American Sign Language!"
  }
]